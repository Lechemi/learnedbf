{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learnedbf import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500000\n",
    "n_clusters_per_class = 1\n",
    "eps= [0.1, 0.01, 0.001]\n",
    "class_sep_list = [0.1, 0.5, 1]\n",
    "n_feat = 5\n",
    "seed = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_dataset(X, y, test_ratio=0.15):\n",
    "    \n",
    "    y = (y == 1)\n",
    "\n",
    "    X_neg = X[~y]\n",
    "    X_pos = X[y]\n",
    "\n",
    "    X_neg_train, X_neg_test = train_test_split(X_neg, test_size=test_ratio, shuffle=True)\n",
    "\n",
    "    X_train = np.concatenate((X_neg_train, X_pos))\n",
    "    y_train = np.array([False]*len(X_neg_train) + [True]*len(X_pos))\n",
    "\n",
    "    return X_neg_test, X_train, y_train\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon = 0.1\n",
      "\tclass sep: 0.1\n",
      "\t\tFPR: 0.1019111111111111\n",
      "\t\tdict_size: {'backup_filter': 264901, 'classifier': 3200}\n",
      "\tclass sep: 0.5\n",
      "\t\tFPR: 0.10195555555555555\n",
      "\t\tdict_size: {'backup_filter': 179583, 'classifier': 3200}\n",
      "\tclass sep: 1\n",
      "\t\tFPR: 0.10113333333333334\n",
      "\t\tdict_size: {'backup_filter': 29599, 'classifier': 3200}\n",
      "epsilon = 0.01\n",
      "\tclass sep: 0.1\n",
      "\t\tFPR: 0.008555555555555556\n",
      "\t\tdict_size: {'backup_filter': 995655, 'classifier': 3200}\n",
      "\tclass sep: 0.5\n",
      "\t\tFPR: 0.009533333333333333\n",
      "\t\tdict_size: {'backup_filter': 646050, 'classifier': 3200}\n",
      "\tclass sep: 1\n",
      "\t\tFPR: 0.009644444444444445\n",
      "\t\tdict_size: {'backup_filter': 314688, 'classifier': 3200}\n",
      "epsilon = 0.001\n",
      "\tclass sep: 0.1\n",
      "\t\tFPR: 0.0011333333333333334\n",
      "\t\tdict_size: {'backup_filter': 2085575, 'classifier': 3200}\n",
      "\tclass sep: 0.5\n",
      "\t\tFPR: 0.0008888888888888889\n",
      "\t\tdict_size: {'backup_filter': 1572109, 'classifier': 3200}\n",
      "\tclass sep: 1\n",
      "\t\tFPR: 0.0009777777777777777\n",
      "\t\tdict_size: {'backup_filter': 493561, 'classifier': 3200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from learnedbf.classifiers import ScoredMLP\n",
    "\n",
    "for epsilon in eps:\n",
    "\n",
    "    print(f\"epsilon = {epsilon}\")\n",
    "\n",
    "    for class_sep in class_sep_list:\n",
    "\n",
    "        print(f\"\\tclass sep: {class_sep}\")\n",
    "\n",
    "        X, y = make_classification(n_samples=n_samples, n_features=n_feat, n_informative=3, \n",
    "                                        n_redundant=1, n_clusters_per_class=1, \n",
    "                                        weights=[0.6, 0.4], flip_y=0, class_sep=class_sep, random_state=seed)\n",
    "        \n",
    "        X_test, X, y = create_training_dataset(X, y, test_ratio=0.15)     \n",
    "\n",
    "        dt = ScoredDecisionTreeClassifier(float_size=32)\n",
    "        dt = ScoredMLP(hidden_layer_sizes=(7,))\n",
    "        slbf = LBF(epsilon=epsilon, classifier=dt, random_state=seed, fpr_test_size=0,\n",
    "                        threshold_test_size=0.2)\n",
    "                        #hyperparameters={'max_leaf_nodes':[5, 10, 20, 35, 50]})\n",
    "        slbf.fit(X, y)\n",
    "        fpr = slbf.estimate_FPR(X_test)\n",
    "        dict_size = slbf.get_size()\n",
    "        print(f\"\\t\\tFPR: {fpr}\")\n",
    "        print(f\"\\t\\tdict_size: {dict_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "500000*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00022222222222222223"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plbf.estimate_FPR(X_neg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
