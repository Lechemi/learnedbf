{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as no\n",
    "from learnedbf import *\n",
    "from learnedbf.BF import *\n",
    "from learnedbf.classifiers import ScoredDecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_bloom_filter_bits(n, p): \n",
    "    \"\"\" \n",
    "    Calculate the optimal number of bits (m) for a Bloom filter. \n",
    "    \n",
    "    Parameters: \n",
    "    n (int): Number of keys \n",
    "    p (float): Desired false positive rate \n",
    "    Returns: \n",
    "    int: Optimal number of bits \n",
    "    \"\"\" \n",
    "    m = -(n * math.log(p)) / math.log(2) \n",
    "    return int(m)\n",
    "\n",
    "def extract_negative_subsets1(X, y, size1, seed):\n",
    "    \"\"\"\n",
    "    Extracts one subset from the negative items and returns it along \n",
    "       with the remaining training data.\n",
    "    \n",
    "    Parameters:\n",
    "    X (array-like): Training set features.\n",
    "    y (array-like): Training set labels.\n",
    "    size1 (int): Fractions of negative items for the first subset.\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    array-like: Two subsets of negative items and the remaining training data.\n",
    "    \"\"\"\n",
    "    # Find the indices of negative items\n",
    "    negative_indices = np.where(y == 0)[0]\n",
    "    np.random.seed(seed)\n",
    "    # Ensure the sizes do not exceed the number of negative items\n",
    "    if size1 >= 1 :\n",
    "        raise ValueError(\"The combined size of subsets exceeds the number of negative items.\")\n",
    "    \n",
    "    # Shuffle the negative indices to ensure random selection\n",
    "    np.random.shuffle(negative_indices)\n",
    "    n = len(y)\n",
    "    size1 = int(size1*n)\n",
    "    \n",
    "    # Extract the subsets\n",
    "    if size1>0:\n",
    "        subset1_indices = negative_indices[:size1]\n",
    "        subset1_X = X[subset1_indices]    \n",
    "        \n",
    "        # Get the remaining data\n",
    "        remaining_indices = np.setdiff1d(np.arange(X.shape[0]), \n",
    "                                     np.concatenate([subset1_indices]))\n",
    "    else:            \n",
    "        raise ValueError(\" extract_negative_subsets: size must be > 0\")\n",
    "    \n",
    "    remaining_X = X[remaining_indices]\n",
    "    remaining_y = y[remaining_indices]\n",
    "    \n",
    "    return subset1_X , remaining_X, remaining_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_samples = 500000\n",
    "n_clusters_per_class = 1\n",
    "eps= [0.1, 0.01, 0.001]\n",
    "class_sep_list = [0.1, 0.5, 1]\n",
    "n_feat = 5\n",
    "seed = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "--------------------------\n",
      "Epsilon: 0.1\n",
      "\t class_sep: 0.1\n",
      "\t\t----- Training SLBF......\n",
      "\t slbf size {'backup_filter': 120110, 'initial_filter': 329478, 'classifier': 7872}\n",
      "\tclass_sep=0.100, FPR=0.101, slbf/bf=0.690\n",
      "\t\t----- Training PLBF......\n",
      "\t plbf size {'backup_filters': 242147, 'classifier': 7872}\n",
      "\tclass_sep=0.100, FPR=0.107, plbf/bf=0.388\n",
      "\t class_sep: 0.5\n",
      "\t\t----- Training SLBF......\n",
      "\t slbf size {'backup_filter': 104121, 'initial_filter': 126313, 'classifier': 7872}\n",
      "\tclass_sep=0.500, FPR=0.134, slbf/bf=0.410\n",
      "\t\t----- Training PLBF......\n",
      "\t plbf size {'backup_filters': 113665, 'classifier': 7872}\n",
      "\tclass_sep=0.500, FPR=0.167, plbf/bf=0.236\n",
      "\t class_sep: 1\n",
      "\t\t----- Training SLBF......\n",
      "\t slbf size {'backup_filter': 5171, 'initial_filter': 374233, 'classifier': 7872}\n",
      "\tclass_sep=1.000, FPR=0.102, slbf/bf=0.587\n",
      "\t\t----- Training PLBF......\n",
      "\t plbf size {'backup_filters': 12146, 'classifier': 7872}\n",
      "\tclass_sep=1.000, FPR=0.101, plbf/bf=0.030\n",
      "----------------------------\n",
      "--------------------------\n",
      "Epsilon: 0.01\n",
      "\t class_sep: 0.1\n",
      "\t\t----- Training SLBF......\n",
      "\t slbf size {'backup_filter': 785125, 'initial_filter': 366828, 'classifier': 7872}\n",
      "\tclass_sep=0.100, FPR=0.010, slbf/bf=0.874\n",
      "\t\t----- Training PLBF......\n",
      "\t plbf size {'backup_filters': 886369, 'classifier': 7872}\n",
      "\tclass_sep=0.100, FPR=0.011, plbf/bf=0.686\n",
      "\t class_sep: 0.5\n",
      "\t\t----- Training SLBF......\n",
      "\t slbf size {'backup_filter': 358580, 'initial_filter': 535331, 'classifier': 7872}\n",
      "\tclass_sep=0.500, FPR=0.011, slbf/bf=0.694\n",
      "\t\t----- Training PLBF......\n",
      "\t plbf size {'backup_filters': 462778, 'classifier': 7872}\n",
      "\tclass_sep=0.500, FPR=0.011, plbf/bf=0.359\n",
      "\t class_sep: 1\n",
      "\t\t----- Training SLBF......\n",
      "\t slbf size {'backup_filter': 84123, 'initial_filter': 343584, 'classifier': 7872}\n",
      "\tclass_sep=1.000, FPR=0.011, slbf/bf=0.335\n",
      "\t\t----- Training PLBF......\n",
      "\t plbf size {'backup_filters': 83828, 'classifier': 7872}\n",
      "\tclass_sep=1.000, FPR=0.010, plbf/bf=0.070\n",
      "----------------------------\n",
      "--------------------------\n",
      "Epsilon: 0.001\n",
      "\t class_sep: 0.1\n",
      "\t\t----- Training SLBF......\n",
      "\t slbf size {'backup_filter': 785125, 'initial_filter': 1325334, 'classifier': 7872}\n",
      "\tclass_sep=0.100, FPR=0.001, slbf/bf=1.065\n",
      "\t\t----- Training PLBF......\n",
      "\t plbf size {'backup_filters': 1811940, 'classifier': 7872}\n",
      "\tclass_sep=0.100, FPR=0.001, plbf/bf=0.918\n",
      "\t class_sep: 0.5\n",
      "\t\t----- Training SLBF......\n",
      "\t slbf size {'backup_filter': 662679, 'initial_filter': 953306, 'classifier': 7872}\n",
      "\tclass_sep=0.500, FPR=0.001, slbf/bf=0.800\n",
      "\t\t----- Training PLBF......\n",
      "\t plbf size {'backup_filters': 1348259, 'classifier': 7872}\n",
      "\tclass_sep=0.500, FPR=0.001, plbf/bf=0.692\n",
      "\t class_sep: 1\n",
      "\t\t----- Training SLBF......\n",
      "\t slbf size {'backup_filter': 84123, 'initial_filter': 1302090, 'classifier': 7872}\n",
      "\tclass_sep=1.000, FPR=0.001, slbf/bf=0.688\n",
      "\t\t----- Training PLBF......\n",
      "\t plbf size {'backup_filters': 267382, 'classifier': 7872}\n",
      "\tclass_sep=1.000, FPR=0.001, plbf/bf=0.145\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ext_LBF_fpr=[]\n",
    "ext_LBF_ratio=[]\n",
    "ext_LBF_space=[]\n",
    "ext_SLBF_fpr=[]\n",
    "ext_SLBF_ratio=[]\n",
    "ext_SLBF_space=[]\n",
    "ext_PLBF_fpr=[]\n",
    "ext_PLBF_ratio=[]\n",
    "ext_PLBF_space=[] \n",
    "ext_FLBF_use_BF = []\n",
    "ext_FLBF_failed = []\n",
    "ext_FLBF_fpr = []\n",
    "ext_FLBF_space = []\n",
    "ext_FLBF_ratio = []\n",
    "\n",
    "ext_for_print = []\n",
    "for j, epsilon in enumerate(eps):\n",
    "    LBF_fpr=[]\n",
    "    LBF_ratio=[]\n",
    "    LBF_space=[]\n",
    "    SLBF_fpr=[]\n",
    "    SLBF_ratio=[]\n",
    "    SLBF_space=[]\n",
    "    PLBF_fpr=[]\n",
    "    PLBF_ratio=[]\n",
    "    PLBF_space=[] \n",
    "    FLBF_fpr = []\n",
    "    FLBF_space = []\n",
    "    FLBF_ratio = []\n",
    "    FLBF_use_BF = []\n",
    "    FLBF_failed = []\n",
    "    for_print = []\n",
    "    print(f\"----------------------------\\n--------------------------\\nEpsilon: {epsilon}\")\n",
    "       \n",
    "    for class_sep in class_sep_list:\n",
    "        print(f\"\\t class_sep: {class_sep}\")        \n",
    "        X, y = make_classification(n_samples=n_samples, n_features=n_feat, n_informative=3, \n",
    "                                    n_redundant=1, n_clusters_per_class=n_clusters_per_class, \n",
    "                                    weights=[0.6, 0.4], flip_y=0, class_sep=class_sep, random_state=seed)\n",
    "          \n",
    "        #print(f\"X.shape: {X.shape}\")\n",
    "        n_pos = np.sum(y==1)\n",
    "        #print(f\"Positives: {n_pos}\")\n",
    "        test_rate= 0.15\n",
    "        X_test1, X, y = extract_negative_subsets1(X, y, test_rate, seed)\n",
    "        \n",
    "        #spazio necessario filtro classico\n",
    "        bf_space = optimal_bloom_filter_bits(n_pos, epsilon)\n",
    "        \n",
    "        ###ALTRI FILTRI APPRESI##################Ã \n",
    "        # print(f\"\\t\\t----- Training LBF......\")\n",
    "        # dt = ScoredDecisionTreeClassifier(float_size=32)        \n",
    "        # lbf = LBF(epsilon=epsilon, classifier=dt, threshold_test_size=0.2, \n",
    "        #           fpr_test_size=0, random_state=seed,\n",
    "        #           hyperparameters={'max_leaf_nodes':[5, 10, 20, 35, 50]})\n",
    "        # dt = lbf.classifier\n",
    "        # lbf.fit(X, y.astype('bool'))\n",
    "        # fpr = lbf.estimate_FPR(X_test1)\n",
    "        # LBF_fpr.append(fpr)\n",
    "        # tmp_bf_space = optimal_bloom_filter_bits(n_pos, fpr)\n",
    "        # size_dict = lbf.get_size()\n",
    "        # print(f\"\\t lbf size {size_dict}\")\n",
    "        # lbf_space = sum([size_dict[k] for k in size_dict])\n",
    "        # LBF_space.append(lbf_space)\n",
    "        # ratio = lbf_space / tmp_bf_space\n",
    "        # LBF_ratio.append(ratio)\n",
    "\n",
    "        #print(f'\\tclass_sep={class_sep:.3f}, FPR={fpr:.3f}, lbf/bf={ratio:.3f}')\n",
    "\n",
    "\n",
    "        print(f\"\\t\\t----- Training SLBF......\")\n",
    "        dt = ScoredDecisionTreeClassifier(float_size=32)\n",
    "        slbf = SLBF(epsilon=epsilon, classifier=dt, random_state=seed, fpr_test_size=0,\n",
    "                    threshold_test_size=0.2,\n",
    "                    hyperparameters={'max_leaf_nodes':[5, 10, 20, 35, 50]})\n",
    "        slbf.fit(X, y.astype('bool'))\n",
    "        fpr = slbf.estimate_FPR(X_test1)\n",
    "        SLBF_fpr.append(fpr)\n",
    "        #print(f\"\\t slbf fpr con DT: {fpr}\")\n",
    "        tmp_bf_space = optimal_bloom_filter_bits(n_pos, fpr)\n",
    "        size_dict = slbf.get_size()\n",
    "        print(f\"\\t slbf size {size_dict}\")\n",
    "        slbf_space = sum([size_dict[k] for k in size_dict])\n",
    "        \n",
    "        SLBF_space.append(slbf_space)\n",
    "        ratio = slbf_space / tmp_bf_space\n",
    "        SLBF_ratio.append(ratio)\n",
    "        print(f'\\tclass_sep={class_sep:.3f}, FPR={fpr:.3f}, slbf/bf={ratio:.3f}')\n",
    "\n",
    "        \n",
    "        \n",
    "        print(f\"\\t\\t----- Training PLBF......\")\n",
    "        dt = ScoredDecisionTreeClassifier(float_size=32)\n",
    "        plbf = PLBF(epsilon=epsilon, classifier=dt, random_state=seed, fpr_test_size=0,\n",
    "                    threshold_test_size=0.2,\n",
    "                    hyperparameters={'max_leaf_nodes':[5, 10, 20, 35, 50]})\n",
    "        plbf.fit(X, y.astype('bool'))\n",
    "        fpr = plbf.estimate_FPR(X_test1)\n",
    "        PLBF_fpr.append(fpr)\n",
    "        tmp_bf_space = optimal_bloom_filter_bits(n_pos, fpr)\n",
    "        size_dict = plbf.get_size()\n",
    "        print(f\"\\t plbf size {size_dict}\")\n",
    "        plbf_space = sum([size_dict[k] for k in size_dict])\n",
    "        \n",
    "        PLBF_space.append(plbf_space)\n",
    "        ratio = plbf_space / tmp_bf_space\n",
    "        PLBF_ratio.append(ratio)\n",
    "        print(f'\\tclass_sep={class_sep:.3f}, FPR={fpr:.3f}, plbf/bf={ratio:.3f}')\n",
    "                  \n",
    "    \n",
    "    ext_SLBF_fpr.append(SLBF_fpr)\n",
    "    ext_SLBF_space.append(SLBF_space)\n",
    "    ext_SLBF_ratio.append(SLBF_ratio)\n",
    "    ext_PLBF_fpr.append(PLBF_fpr)\n",
    "    ext_PLBF_space.append(PLBF_space)\n",
    "    ext_PLBF_ratio.append(PLBF_ratio)\n",
    "\n",
    "    ext_LBF_fpr.append(LBF_fpr)    \n",
    "    ext_LBF_space.append(LBF_space)\n",
    "    ext_LBF_ratio.append(LBF_ratio)\n",
    "        #plot_results(epsilon, inner_dim_list, FLF_fpr, FLF_space, inner_classif, n, bf_space)\n",
    "    #plot_results(epsilon, for_print, FLF_fpr, FLF_space, FLF_occ, inner_classif, n_pos, bf_space, cur_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epsilon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dt \u001b[38;5;241m=\u001b[39m ScoredDecisionTreeClassifier(float_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)        \n\u001b[0;32m----> 2\u001b[0m lbf \u001b[38;5;241m=\u001b[39m LBF(epsilon\u001b[38;5;241m=\u001b[39m\u001b[43mepsilon\u001b[49m, classifier\u001b[38;5;241m=\u001b[39mdt, threshold_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \n\u001b[1;32m      3\u001b[0m             fpr_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m      4\u001b[0m             hyperparameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_leaf_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m50\u001b[39m]})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epsilon' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ext_LBF_fpr=[]\n",
    "ext_LBF_ratio=[]\n",
    "ext_LBF_space=[]\n",
    "ext_SLBF_fpr=[]\n",
    "ext_SLBF_ratio=[]\n",
    "ext_SLBF_space=[]\n",
    "ext_PLBF_fpr=[]\n",
    "ext_PLBF_ratio=[]\n",
    "ext_PLBF_space=[] \n",
    "ext_FLBF_use_BF = []\n",
    "ext_FLBF_failed = []\n",
    "ext_FLBF_fpr = []\n",
    "ext_FLBF_space = []\n",
    "ext_FLBF_ratio = []\n",
    "\n",
    "ext_for_print = []\n",
    "for j, m in enumerate([200000, 500000, 1000000]):\n",
    "    LBF_fpr=[]\n",
    "    LBF_ratio=[]\n",
    "    LBF_space=[]\n",
    "    SLBF_fpr=[]\n",
    "    SLBF_ratio=[]\n",
    "    SLBF_space=[]\n",
    "    PLBF_fpr=[]\n",
    "    PLBF_ratio=[]\n",
    "    PLBF_space=[] \n",
    "    FLBF_fpr = []\n",
    "    FLBF_space = []\n",
    "    FLBF_ratio = []\n",
    "    FLBF_use_BF = []\n",
    "    FLBF_failed = []\n",
    "    for_print = []\n",
    "    print(f\"----------------------------\\n--------------------------\\nEpsilon: {epsilon}\")\n",
    "       \n",
    "    for class_sep in class_sep_list:\n",
    "        print(f\"\\t class_sep: {class_sep}\")        \n",
    "        X, y = make_classification(n_samples=n_samples, n_features=n_feat, n_informative=3, \n",
    "                                    n_redundant=1, n_clusters_per_class=n_clusters_per_class, \n",
    "                                    weights=[0.6, 0.4], flip_y=0, class_sep=class_sep, random_state=seed)\n",
    "          \n",
    "        #print(f\"X.shape: {X.shape}\")\n",
    "        n_pos = np.sum(y==1)\n",
    "        #print(f\"Positives: {n_pos}\")\n",
    "        test_rate= 0.15\n",
    "        X_test1, X, y = extract_negative_subsets1(X, y, test_rate, seed)\n",
    "        \n",
    "        #spazio necessario filtro classico\n",
    "        #bf_space = optimal_bloom_filter_bits(n_pos, epsilon)\n",
    "        \n",
    "        ###ALTRI FILTRI APPRESI##################Ã \n",
    "        # print(f\"\\t\\t----- Training LBF......\")\n",
    "        # dt = ScoredDecisionTreeClassifier(float_size=32)        \n",
    "        # lbf = LBF(epsilon=epsilon, classifier=dt, threshold_test_size=0.2, \n",
    "        #           fpr_test_size=0, random_state=seed,\n",
    "        #           hyperparameters={'max_leaf_nodes':[5, 10, 20, 35, 50]})\n",
    "        # dt = lbf.classifier\n",
    "        # lbf.fit(X, y.astype('bool'))\n",
    "        # fpr = lbf.estimate_FPR(X_test1)\n",
    "        # LBF_fpr.append(fpr)\n",
    "        # tmp_bf_space = optimal_bloom_filter_bits(n_pos, fpr)\n",
    "        # size_dict = lbf.get_size()\n",
    "        # print(f\"\\t lbf size {size_dict}\")\n",
    "        # lbf_space = sum([size_dict[k] for k in size_dict])\n",
    "        # LBF_space.append(lbf_space)\n",
    "        # ratio = lbf_space / tmp_bf_space\n",
    "        # LBF_ratio.append(ratio)\n",
    "\n",
    "        #print(f'\\tclass_sep={class_sep:.3f}, FPR={fpr:.3f}, lbf/bf={ratio:.3f}')\n",
    "\n",
    "\n",
    "        print(f\"\\t\\t----- Training SLBF......\")\n",
    "        dt = ScoredDecisionTreeClassifier(float_size=32)\n",
    "        slbf = SLBF(m=m, classifier=dt, random_state=seed, fpr_test_size=0,\n",
    "                    threshold_test_size=0.2,\n",
    "                    hyperparameters={'max_leaf_nodes':[5, 10, 20, 35, 50]})\n",
    "        slbf.fit(X, y.astype('bool'))\n",
    "        fpr = slbf.estimate_FPR(X_test1)\n",
    "        SLBF_fpr.append(fpr)\n",
    "        #print(f\"\\t slbf fpr con DT: {fpr}\")\n",
    "        tmp_bf_space = optimal_bloom_filter_bits(n_pos, fpr)\n",
    "        size_dict = slbf.get_size()\n",
    "        print(f\"\\t slbf size {size_dict}\")\n",
    "        slbf_space = sum([size_dict[k] for k in size_dict])\n",
    "        \n",
    "        SLBF_space.append(slbf_space)\n",
    "        ratio = slbf_space / tmp_bf_space\n",
    "        SLBF_ratio.append(ratio)\n",
    "        print(f'\\tclass_sep={class_sep:.3f}, FPR={fpr:.3f}, slbf/bf={ratio:.3f}')\n",
    "\n",
    "        \n",
    "        \n",
    "        print(f\"\\t\\t----- Training PLBF......\")\n",
    "        dt = ScoredDecisionTreeClassifier(float_size=32)\n",
    "        plbf = PLBF(m=m, classifier=dt, random_state=seed, fpr_test_size=0,\n",
    "                    threshold_test_size=0.2,\n",
    "                    hyperparameters={'max_leaf_nodes':[5, 10, 20, 35, 50]})\n",
    "        plbf.fit(X, y.astype('bool'))\n",
    "        fpr = plbf.estimate_FPR(X_test1)\n",
    "        PLBF_fpr.append(fpr)\n",
    "        tmp_bf_space = optimal_bloom_filter_bits(n_pos, fpr)\n",
    "        size_dict = plbf.get_size()\n",
    "        print(f\"\\t plbf size {size_dict}\")\n",
    "        plbf_space = sum([size_dict[k] for k in size_dict])\n",
    "        \n",
    "        PLBF_space.append(plbf_space)\n",
    "        ratio = plbf_space / tmp_bf_space\n",
    "        PLBF_ratio.append(ratio)\n",
    "        print(f'\\tclass_sep={class_sep:.3f}, FPR={fpr:.3f}, plbf/bf={ratio:.3f}')\n",
    "                  \n",
    "    \n",
    "    ext_SLBF_fpr.append(SLBF_fpr)\n",
    "    ext_SLBF_space.append(SLBF_space)\n",
    "    ext_SLBF_ratio.append(SLBF_ratio)\n",
    "    ext_PLBF_fpr.append(PLBF_fpr)\n",
    "    ext_PLBF_space.append(PLBF_space)\n",
    "    ext_PLBF_ratio.append(PLBF_ratio)\n",
    "\n",
    "    ext_LBF_fpr.append(LBF_fpr)    \n",
    "    ext_LBF_space.append(LBF_space)\n",
    "    ext_LBF_ratio.append(LBF_ratio)\n",
    "        #plot_results(epsilon, inner_dim_list, FLF_fpr, FLF_space, inner_classif, n, bf_space)\n",
    "    #plot_results(epsilon, for_print, FLF_fpr, FLF_space, FLF_occ, inner_classif, n_pos, bf_space, cur_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lbf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m test_rate\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.15\u001b[39m\n\u001b[1;32m      9\u001b[0m X_test1, X, y \u001b[38;5;241m=\u001b[39m extract_negative_subsets1(X, y, test_rate, seed)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mlbf\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X, y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m dt \u001b[38;5;241m=\u001b[39m lbf\u001b[38;5;241m.\u001b[39mclassifier\n\u001b[1;32m     13\u001b[0m fpr \u001b[38;5;241m=\u001b[39m lbf\u001b[38;5;241m.\u001b[39mestimate_FPR(X_test1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lbf' is not defined"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=n_samples, n_features=n_feat, n_informative=3, \n",
    "                                    n_redundant=1, n_clusters_per_class=1, \n",
    "                                    weights=[0.6, 0.4], flip_y=0, class_sep=0.5, random_state=seed)\n",
    "\n",
    "#print(f\"X.shape: {X.shape}\")\n",
    "n_pos = np.sum(y==1)\n",
    "#print(f\"Positives: {n_pos}\")\n",
    "test_rate= 0.15\n",
    "X_test1, X, y = extract_negative_subsets1(X, y, test_rate, seed)\n",
    "\n",
    "lbf.fit(X, y.astype('bool'))\n",
    "dt = lbf.classifier\n",
    "fpr = lbf.estimate_FPR(X_test1)\n",
    "\n",
    "print(f\"\\t\\t FPR lbf: {fpr}\")\n",
    "\n",
    "#LBF_fpr.append(fpr)\n",
    "tmp_bf_space = optimal_bloom_filter_bits(n_pos, fpr)\n",
    "size_dict = lbf.get_size()\n",
    "print(f\"\\t lbf size {size_dict}\")\n",
    "lbf_space = sum([size_dict[k] for k in size_dict])\n",
    "ratio = lbf_space / tmp_bf_space\n",
    "\n",
    "\n",
    "print(f'\\tclass_sep={class_sep:.3f}, FPR={fpr:.3f}, lbf/bf={ratio:.3f}')\n",
    "\n",
    "\n",
    "print(f\"\\t\\t----- Training SLBF......\")\n",
    "#dt = ScoredDecisionTreeClassifier(float_size=32)\n",
    "slbf = SLBF(epsilon=epsilon, classifier=dt, random_state=seed, fpr_test_size=0,\n",
    "        threshold_test_size=0.2)#,\n",
    "       #  hyperparameters={'max_leaf_nodes':[5, 10, 20, 35, 50]})\n",
    "slbf.fit(X, y.astype('bool'))\n",
    "\n",
    "fpr = slbf.estimate_FPR(X_test1)\n",
    "print(f\"\\t\\t FPR slbf: {fpr} \")\n",
    "\n",
    "fpr = slbf.estimate_FPR(X_test1)\n",
    "SLBF_fpr.append(fpr)\n",
    "print(f\"\\t slbf fpr con DT: {fpr}\")\n",
    "tmp_bf_space = optimal_bloom_filter_bits(n_pos, fpr)\n",
    "size_dict = slbf.get_size()\n",
    "print(f\"\\t slbf size {size_dict}\")\n",
    "slbf_space = sum([size_dict[k] for k in size_dict])\n",
    "\n",
    "#SLBF_space.append(slbf_space)\n",
    "ratio = slbf_space / tmp_bf_space\n",
    "#SLBF_ratio.append(ratio)\n",
    "print(f'\\tclass_sep={class_sep:.3f}, FPR={fpr:.3f}, slbf/bf={ratio:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t FPR lbf: 9.333333333333333e-05\n",
      "\t lbf size {'backup_filter': 2724900, 'classifier': 7872}\n",
      "\tclass_sep=1.000, FPR=0.000, lbf/bf=1.021\n",
      "\t\t----- Training SLBF......\n",
      "\t\t FPR slbf: 0.00092 \n",
      "\t slbf fpr con DT: 0.00092\n",
      "\t slbf size {'backup_filter': 662679, 'initial_filter': 953306, 'classifier': 7872}\n",
      "\tclass_sep=1.000, FPR=0.001, slbf/bf=0.805\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=n_samples, n_features=n_feat, n_informative=3, \n",
    "                                    n_redundant=1, n_clusters_per_class=1, \n",
    "                                    weights=[0.6, 0.4], flip_y=0, class_sep=0.5, random_state=seed)\n",
    "\n",
    "#print(f\"X.shape: {X.shape}\")\n",
    "n_pos = np.sum(y==1)\n",
    "#print(f\"Positives: {n_pos}\")\n",
    "test_rate= 0.15\n",
    "X_test1, X, y = extract_negative_subsets1(X, y, test_rate, seed)\n",
    "\n",
    "lbf.fit(X, y.astype('bool'))\n",
    "dt = lbf.classifier\n",
    "fpr = lbf.estimate_FPR(X_test1)\n",
    "\n",
    "print(f\"\\t\\t FPR lbf: {fpr}\")\n",
    "\n",
    "#LBF_fpr.append(fpr)\n",
    "tmp_bf_space = optimal_bloom_filter_bits(n_pos, fpr)\n",
    "size_dict = lbf.get_size()\n",
    "print(f\"\\t lbf size {size_dict}\")\n",
    "lbf_space = sum([size_dict[k] for k in size_dict])\n",
    "ratio = lbf_space / tmp_bf_space\n",
    "\n",
    "\n",
    "print(f'\\tclass_sep={class_sep:.3f}, FPR={fpr:.3f}, lbf/bf={ratio:.3f}')\n",
    "\n",
    "\n",
    "print(f\"\\t\\t----- Training SLBF......\")\n",
    "dt = ScoredDecisionTreeClassifier(float_size=32)\n",
    "slbf = SLBF(epsilon=epsilon, classifier=dt, random_state=seed, fpr_test_size=0,\n",
    "        threshold_test_size=0.2,\n",
    "       hyperparameters={'max_leaf_nodes':[5, 10, 20, 35, 50]})\n",
    "slbf.fit(X, y.astype('bool'))\n",
    "\n",
    "fpr = slbf.estimate_FPR(X_test1)\n",
    "print(f\"\\t\\t FPR slbf: {fpr} \")\n",
    "\n",
    "fpr = slbf.estimate_FPR(X_test1)\n",
    "SLBF_fpr.append(fpr)\n",
    "print(f\"\\t slbf fpr con DT: {fpr}\")\n",
    "tmp_bf_space = optimal_bloom_filter_bits(n_pos, fpr)\n",
    "size_dict = slbf.get_size()\n",
    "print(f\"\\t slbf size {size_dict}\")\n",
    "slbf_space = sum([size_dict[k] for k in size_dict])\n",
    "\n",
    "#SLBF_space.append(slbf_space)\n",
    "ratio = slbf_space / tmp_bf_space\n",
    "#SLBF_ratio.append(ratio)\n",
    "print(f'\\tclass_sep={class_sep:.3f}, FPR={fpr:.3f}, slbf/bf={ratio:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
